{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "print(\"Number of cpu : \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Preprocessing template. \n",
    "\n",
    "Why use Pool() and not Process()?\n",
    "\n",
    "https://towardsdatascience.com/speed-up-your-algorithms-part-3-parallelization-4d95c0888748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to crate a figure and get instance of Axis.\n",
    "def axex(size):\n",
    "    fig = plt.figure(figsize=(size[0],size[1])) # define plot area\n",
    "    ax = fig.gca() # define axis  \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('./Hackathon/Data/train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Count of unique member id\n",
    "len(loan_data['UniqueID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loan_data['Date.of.Birth'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_data['loan_amnt'].isnull().sum()\n",
    "\n",
    "# Function to find sum and percent of missing values for each column.\n",
    "# Remove the one's that have no missing values.\n",
    "\n",
    "def missing_values(df):\n",
    "#     Sum null values. Then divide by the total occurrence\n",
    "    sum = (df == 0).sum() \n",
    "    percent = (df == 0).sum()/len(df)*100\n",
    "    missing_stats = pd.concat([sum, percent], axis=1).rename(\n",
    "        columns = {\n",
    "            0: 'Number',\n",
    "            1: 'Percent'\n",
    "        }\n",
    "    )\n",
    "#   drop all rows that are equal to 0.\n",
    "    missing_stats = missing_stats[missing_stats.iloc[:,1] != 0]\n",
    "    missing_stats.reset_index(inplace=True)\n",
    "    missing_stats.sort_values('Percent', inplace=True)\n",
    "    \n",
    "    return missing_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values(loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Removing columns with more than 70% of missing data.\n",
    "# Get a threshold of what is 30% \n",
    "# print(loan_data.count())\n",
    "\n",
    "# temp = [i for i in loan_data.count()<887379 *0.30]\n",
    "# loan_data.drop(loan_data.columns[temp],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan data vs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = axex([10,10])\n",
    "\n",
    "# Average annual income plot\n",
    "loan_data[['loan_default', 'Current_pincode_ID']].groupby(['Current_pincode_ID']).sum().plot(ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTV vs distribution\n",
    "ltv vs amount\n",
    "LD of salaried and self_employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate(df,col,vartype,hue =None):\n",
    "    \n",
    "    '''\n",
    "    Univariate function will plot the graphs based on the parameters.\n",
    "    df      : dataframe name\n",
    "    col     : Column name\n",
    "    vartype : variable type : continuos or categorical\n",
    "                Continuos(0)   : Distribution, Violin & Boxplot will be plotted.\n",
    "                Categorical(1) : Countplot will be plotted.\n",
    "    hue     : It's only applicable for categorical analysis.\n",
    "    \n",
    "    '''\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    \n",
    "    if vartype == 0:\n",
    "        fig, ax=plt.subplots(nrows =1,ncols=3,figsize=(20,8))\n",
    "        ax[0].set_title(\"Distribution Plot\")\n",
    "        sns.distplot(df[col],ax=ax[0])\n",
    "        ax[1].set_title(\"Violin Plot\")\n",
    "        sns.violinplot(data =df, x=col,ax=ax[1], inner=\"quartile\")\n",
    "        ax[2].set_title(\"Box Plot\")\n",
    "        sns.boxplot(data =df, x=col,ax=ax[2],orient='v')\n",
    "    \n",
    "    if vartype == 1:\n",
    "        temp = pd.Series(data = hue)\n",
    "        print(len(temp.unique()))\n",
    "        fig, ax = plt.subplots()\n",
    "        width = len(df[col].unique()) + 6 + 4*len(temp.unique())\n",
    "        fig.set_size_inches(width , 7)\n",
    "        ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue) \n",
    "        if len(temp.unique()) > 0:\n",
    "            for p in ax.patches:\n",
    "                if p.get_height() > 0:\n",
    "                    ax.annotate('{:1.1f}%'.format((p.get_height()*100)/float(len(loan_data))), (p.get_x()+0.05, p.get_height()+20))  \n",
    "        else:\n",
    "            for p in ax.patches:\n",
    "                ax.annotate(p.get_height(), (p.get_x()+0.32, p.get_height()+20)) \n",
    "        del temp\n",
    "    else:\n",
    "        exit\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.Series(data = 'hue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dibursed_amount\n",
    "univariate(df=loan_data,col='disbursed_amount',vartype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_data.loc[(loan_data['disbursed_amount'] > 180000)]['loan_default']\n",
    "\n",
    "loan_data.disbursed_amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.loc[(loan_data['disbursed_amount'] > 100000) &\\\n",
    "              (loan_data['loan_default'] == 0)]['loan_default'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove rows containing anomalies (amt > 1lk)? what do these anomalies mean?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df=loan_data,col='asset_cost',vartype=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__drop asset_cost > 1lkh?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df=loan_data,col='ltv',vartype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.ltv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.loc[(loan_data['ltv'] < 48) & (loan_data['disbursed_amount'] > 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of cns score\n",
    "univariate(df=loan_data,col='PERFORM_CNS.SCORE',vartype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['PERFORM_CNS.SCORE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default and no credit rating score\n",
    "x = len(loan_data.loc[(loan_data['PERFORM_CNS.SCORE'] == 0) &\\\n",
    "              (loan_data['loan_default'] == 1)])\n",
    "\n",
    "y = len(loan_data.loc[(loan_data['PERFORM_CNS.SCORE'] == 0)])\n",
    "\n",
    "# percent defaulted with no CNS score.\n",
    "print(x/y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['PRIMARY.INSTAL.AMT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of EMI amount\n",
    "# univariate(df=loan_data,col='PRIMARY.INSTAL.AMT',vartype=0)\n",
    "ax = axex([10,10])\n",
    "loan_data['PRIMARY.INSTAL.AMT'].plot.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_data['loan_default'].value_counts())\n",
    "print(50611/182543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment type count plot\n",
    "univariate(df=loan_data,col='Employment.Type',vartype=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df=loan_data[(loan_data['Employment.Type'] == 'Salaried')],col='loan_default',vartype=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19910/77948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df=loan_data[(loan_data['Employment.Type'] == 'Self employed')],col='loan_default',vartype=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "29057/98578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of loan applicant from each state\n",
    "univariate(df=loan_data,col='State_ID',vartype=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# LD vs Sate\n",
    "univariate(df=loan_data,col='State_ID',vartype=1, hue='loan_default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of instances per manufacturer\n",
    "univariate(df=loan_data,col='manufacturer_id',vartype=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loan_data.loc[(loan_data['manufacturer_id'] == 152) |\\\n",
    "              (loan_data['manufacturer_id'] == 153) |\\\n",
    "              (loan_data['manufacturer_id'] == 156)\n",
    "             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop manu_id 152, 153, 156 ? total == 19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['manufacturer_id'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.loc[(loan_data['manufacturer_id'] == 153) & (loan_data['loan_default']==1)]['loan_default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------ANAAAALYSISSSSSSSSS-------------\n",
    "# fig, ax = plt.subplots()\n",
    "# fig.set_size_inches(20 ,20 )\n",
    "# ax = sns.countplot(data = loan_data, x= 'manufacturer_id', order=loan_data['manufacturer_id'].\\\n",
    "#                    value_counts().index,hue = 'loan_default')\n",
    "# for p in ax.patches:\n",
    "# #     \n",
    "#     if p.get_height() > 0:\n",
    "#         print(p.get_height())\n",
    "#         ax.annotate('{:1.1f}%'.format((p.get_height()*100)/float(len(loan_data))),\\\n",
    "#                     (p.get_x()+0.05, p.get_height()+20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LD vs manufacturer\n",
    "\n",
    "'''\n",
    "    152 and 156 have no defaults. p.get_height() is returning a nan value if value = 0.\n",
    "    153 has 4 loan_defaults. percentage base is entire df len. therefore 0% for 153 comes \n",
    "    after flooring the percent value.\n",
    "    '''\n",
    "univariate(df=loan_data,col='manufacturer_id',vartype=1, hue='loan_default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count of instances per branch_id\n",
    "# univariate(df=loan_data,col='branch_id',vartype=1)\n",
    "\n",
    "# LD grouped by branchid. \n",
    "\n",
    "ax = axex([15,10])\n",
    "\n",
    "loan_data[['loan_default', 'branch_id']].\\\n",
    "    groupby('branch_id').\\\n",
    "    count().\\\n",
    "    plot.bar(ax=ax)\n",
    "\n",
    "\n",
    "ax.set_title('LD vs Branch')\n",
    "ax.set_xlabel('Branch')\n",
    "ax.set_ylabel('LD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20 ,20)\n",
    "ax = sns.countplot(data = loan_data, x= 'branch_id', order=loan_data['branch_id'].\\\n",
    "                   value_counts().index,hue = 'loan_default')\n",
    "for p in ax.patches:\n",
    "#     \n",
    "    if p.get_height() > 0:\n",
    "        ax.annotate('{:1.1f}'.format((p.get_height())),\\\n",
    "                    (p.get_x()+0.05, p.get_height()+20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate plots \n",
    "__relation of 2 features to the target(categorical type)__ Used to check correlation of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"asset_cost\", y=\"disbursed_amount\", hue=\"loan_default\", data=loan_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Probably confirms removing val > 1lkh based on disbursed_amount and asset_cost distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"loan_default\", y=\"disbursed_amount\", data=loan_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "sns.relplot(data =loan_data, x='PRIMARY.INSTAL.AMT', y='disbursed_amount', hue ='loan_default')\n",
    "plt.title('EMI vs Disbursed Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_correlation = loan_data.corr()\n",
    "# loan_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(14, 9))\n",
    "# sns.heatmap(loan_correlation, \n",
    "#             xticklabels=loan_correlation.columns.values,\n",
    "#             yticklabels=loan_correlation.columns.values,annot= True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing duration to number of months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['AVERAGE.ACCT.AGE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def pat1(x):\n",
    "    result = re.search('([0-9]*) [0-9]*', x)\n",
    "    return int(result.group(1))\n",
    "\n",
    "def pat2(x):\n",
    "    result = re.search('[0-9]* ([0-9]*)', x)\n",
    "    return int(result.group(1))\n",
    "    \n",
    "def change_to_months(loan_data):\n",
    "    loan_data['avg_tenure'] = loan_data['AVERAGE.ACCT.AGE'].str.replace(r'[a-zA-Z]*', '')\n",
    "    loan_data['cred_hist_len'] = loan_data['CREDIT.HISTORY.LENGTH'].str.replace(r'[a-zA-Z]*', '')\n",
    "    loan_data['avg_tenure'] = loan_data['avg_tenure'].apply(lambda x: pat1(x)*12 + pat2(x))\n",
    "    loan_data['cred_hist_len'] = loan_data['cred_hist_len'].apply(lambda x: pat1(x)*12 + pat2(x))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create age from DOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_age(loan_data):\n",
    "    now = pd.Timestamp('now')\n",
    "    loan_data['Date.of.Birth'] = pd.to_datetime(loan_data['Date.of.Birth'])\n",
    "    loan_data['Date.of.Birth'] = loan_data['Date.of.Birth'].where(loan_data['Date.of.Birth'] < now, loan_data['Date.of.Birth'] -  np.timedelta64(100, 'Y'))\n",
    "    loan_data['age'] = (now - loan_data['Date.of.Birth']).astype('<m8[Y]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert employment type to numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_binary(loan_data):\n",
    "    # 1 - Salaried\n",
    "    # 0 - Self-employed\n",
    "    loan_data['Employment.Type'] = loan_data['Employment.Type'].map({'Salaried': 1, 'Self employed' : 0})\n",
    "    loan_data.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting all flags to one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_traceability(loan_data):\n",
    "    loan_data['traceability'] = (loan_data['MobileNo_Avl_Flag'] + loan_data['Aadhar_flag'] + loan_data['PAN_flag'] + loan_data['VoterID_flag'] + loan_data['Driving_flag'] + loan_data['Passport_flag']) / 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should the flags be dropped? Test with model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping entries of asset_cost > 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_asset_cost_outliers(df):\n",
    "    df = df.drop(df[df['disbursed_amount'] > 100000].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call functions on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./Hackathon/Data/test.csv')\n",
    "\n",
    "change_to_months(loan_data)\n",
    "change_to_age(loan_data)\n",
    "change_to_binary(loan_data)\n",
    "create_traceability(loan_data)\n",
    "drop_asset_cost_outliers(loan_data)\n",
    "\n",
    "change_to_months(test)\n",
    "change_to_age(test)\n",
    "change_to_binary(test)\n",
    "create_traceability(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.isnull().sum())\n",
    "print(\"-----------\")\n",
    "print(loan_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data['traceability'].value_counts()\n",
    "univariate(df=loan_data, col='traceability', vartype=1, hue='loan_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "# from sklearn import metrics, cross_validation\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = loan_data.copy(deep=True)\n",
    "df_test_model = test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop([\n",
    "    'UniqueID',\n",
    "    'branch_id',\n",
    "    'supplier_id',\n",
    "    'manufacturer_id',\n",
    "    'Current_pincode_ID',\n",
    "    'VoterID_flag',\n",
    "    'Aadhar_flag'.\n",
    "    'MobileNo_Avl_Flag',\n",
    "    'PAN_flag',\n",
    "    'VoterID_flag',\n",
    "    'Driving_flag',\n",
    "    'Passport_flag',\n",
    "    'Date.of.Birth',\n",
    "    'AVERAGE.ACCT.AGE',\n",
    "    'CREDIT.HISTORY.LENGTH',\n",
    "    'PERFORM_CNS.SCORE.DESCRIPTION',\n",
    "    'Employee_code_ID',\n",
    "    'State_ID',\n",
    "    'DisbursalDate'\n",
    "], axis=1, inplace=True)\n",
    "\n",
    "df_test_model.drop([\n",
    "    'UniqueID',\n",
    "    'branch_id',\n",
    "    'supplier_id',\n",
    "    'manufacturer_id',\n",
    "    'Current_pincode_ID',\n",
    "    'VoterID_flag',\n",
    "    'Aadhar_flag',\n",
    "    'MobileNo_Avl_Flag',\n",
    "    'PAN_flag',\n",
    "    'VoterID_flag',\n",
    "    'Driving_flag',\n",
    "    'Passport_flag',\n",
    "    'Date.of.Birth',\n",
    "    'AVERAGE.ACCT.AGE',\n",
    "    'CREDIT.HISTORY.LENGTH',\n",
    "    'PERFORM_CNS.SCORE.DESCRIPTION',\n",
    "    'Employee_code_ID',\n",
    "    'State_ID',\n",
    "    'DisbursalDate'\n",
    "], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.rename(index=str, columns={\"loan_default\": \"Target\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the training dataset as 50-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rmse(reg): \n",
    "    #   Train test split  \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df_model.drop('Target',axis=1),df_model['Target'],test_size=0.20, stratify=y, random_state=154)\n",
    "    X_train = df_model.drop('Target', axis=1)\n",
    "    y_train = df_model['Target']\n",
    "    X_test = df_test_model.copy(deep=True)\n",
    "    X_train.index = X_train.index.astype('int64')\n",
    "    y_train.index = y_train.index.astype('int64')\n",
    "    X_test.index = X_test.index.astype('int64')\n",
    "    # Balancing the dataset\n",
    "    \n",
    "#     np_y_train = y_train.values\n",
    "#     np_X_train = X_train.values\n",
    "#     total_num_of_ones = int(np.sum(y_train))\n",
    "#     # print(total_num_of_ones)\n",
    "#     zero_counter = 0\n",
    "#     indices_to_remove = []\n",
    "\n",
    "#     for i in range(np_y_train.shape[0]):\n",
    "#         if np_y_train[i] == 0:\n",
    "#             if zero_counter < total_num_of_ones:\n",
    "#                 zero_counter += 1\n",
    "#             else:\n",
    "#                 indices_to_remove.append(i)\n",
    "\n",
    "#     X_train = np.delete(np_X_train, indices_to_remove, axis=0)\n",
    "#     y_train = np.delete(np_y_train, indices_to_remove, axis=0)\n",
    "\n",
    "#     print(len(X_train))\n",
    "#     print(len(y_train))\n",
    "    \n",
    "    # Normalising the dataset     \n",
    "#     sc = StandardScaler()\n",
    "#     X_train = sc.fit_transform(X_train)\n",
    "#     X_test=sc.transform(X_test)\n",
    "    \n",
    "#     # Fit the model\n",
    "#     reg.fit(X_train, y_train)\n",
    "    \n",
    "#     res = cross_val_score(reg, X_train, y_train, cv=10, scoring='accuracy')\n",
    "#     print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "    \n",
    "#     y_out = reg.predict(X_test)\n",
    "# #     print(len(y_out))\n",
    "\n",
    "    # Implementing XGBoost and stratified k-fold\n",
    "    \n",
    "    # Converting X_train and y_train to a DF\n",
    "#     X_train = pd.DataFrame(X_train)\n",
    "#     y_train = pd.DataFrame(y_train)\n",
    "    \n",
    "    param_grid = [{'min_child_weight': np.arange(0.1, 10.1, 0.1)}]\n",
    "    i=1\n",
    "    kf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "    for train_index,test_index in kf.split(X_train,y_train):\n",
    "        print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "        xtr,xvl = X_train.loc[train_index],X_train.loc[test_index]\n",
    "        ytr,yvl = y_train[train_index],y_train[test_index]\n",
    "        model = GridSearchCV(XGBClassifier(n_estimators=10, n_jobs=4), param_grid, cv=10, scoring= 'f1',iid=True)\n",
    "        model.fit(xtr, ytr)\n",
    "        print (model.best_params_)\n",
    "        pred=model.predict(X_test)\n",
    "        print('accuracy_score',accuracy_score(yvl,pred))\n",
    "        i+=1\n",
    "    \n",
    "    y_out = predict(X_test)\n",
    "    op_df = pd.DataFrame({'UniqueID': test['UniqueID'], 'loan_default': y_out})\n",
    "    print(op_df['loan_default'].value_counts())\n",
    "    op_df.to_csv(path_or_buf='./rand_for.csv', index=False, index_label='UniqueID')\n",
    "#     print('Accuracy score: ')\n",
    "#     print(reg.score(X_test, y_test))\n",
    "\n",
    "#     error = np.sqrt(mean_squared_error(y_test, y_out))\n",
    "                                \n",
    "#     print(str(error)+ repr(reg)[0:4]) #using repr to get initials of the name of the classifier that this run used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "#Add imported classes of classification models to be used.\n",
    "regressors_list = [LogisticRegression(), RandomForestClassifier()] \n",
    "pool = Pool(1)\n",
    "pool.map(find_rmse,regressors_list)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
